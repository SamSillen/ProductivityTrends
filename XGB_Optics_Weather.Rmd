---
title: "Chl-a Model : Optical Only (XgBoost)"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Workflow
```{r}

## 1) Read in training file ; filter, calculate band ratios, and remove correlated variables 


## 2) Set up train / test splits for random CV 


## 3) Hypertune xgboost parameters and save as 'best_params' 


## 4) Train final model with best params , look at evaluation metrics from test data

```

Packages
```{r}
library(tidyverse)
library(xgboost)
library(caret)
library(ggplot2)
```





1) Read in training file ; filter, calculate band ratios, and remove correlated variables 
```{r}
training <- read.csv("C:/Users/samsi/Dropbox/training.csv") 

baseDir <- "C:/Users/samsi/Dropbox/"

source(paste0(baseDir,'Sam_Matt_Collabs/ML_utils.R'))

training <- training %>%
  filter(pixelCount > 9, 
         clouds < 50,    
         across(c(blue, green, red, nir, swir1, swir2), ~ .x > 0 & .x < 2000)) %>% # taken from Simon Code (reasonable reflectance values ?)
  mutate(dWL = fui.hue(red, green, blue),
         red_to_blue = red/blue,
         red_to_nir = red/nir,
         nir_to_red = nir/red,
         blue_to_green = blue/green,
         green_to_blue = green/blue,
         blue_min_red_ovr_green = (blue-red)/(green),
         nir_sac = nir-swir1,
         nir_sac2 = nir-1.03*swir1,
         nir_min_red = nir-red,
         id = row_number())
        

#Check for dups

test <- training %>%
  distinct(blue, red, green, dWL, lagoslakeid, date, chl_a)

#dups exist i guess

#checking for correlated optical vars

optical_dat <- training %>%
  select(blue, green, red, dWL, red_to_blue, red_to_nir, nir_to_red, blue_to_green, green_to_blue, blue_min_red_ovr_green, nir_sac, nir_sac2, nir_min_red)

corr.matrix <- cor(optical_dat)

corr <- findCorrelation(corr.matrix, cutoff = 0.9)

hc = sort(corr)

reduced_Data = corr.matrix[,-c(hc)]

# uncorrelated vars: blue,  dwl, red_to_blue,red_to_nir, nir_to_red, green_to_blue, nir_sac, nir_min_red

data <- training %>%
  select(blue, dWL, nir, swir2, red_to_blue, red_to_nir, nir_to_red, green_to_blue, nir_sac, nir_min_red, chl_a, lagoslakeid,id, mean_temp_14_day, date, wind)

#remove dups by using distinct

data <- data %>%
  distinct(blue, dWL, nir, swir2, red_to_blue, red_to_nir, nir_to_red, green_to_blue, nir_sac, nir_min_red, chl_a, lagoslakeid,id, mean_temp_14_day, date, wind)


data$in_situ_cat <- cut(data$chl_a, breaks = c(0, 2.6, 7, 200), labels = c('oligotrophic', 'mesotrophic', 'eutrophic'))
         
#For xgboost categorical preds

data$in_situ_cat <- as.numeric(as.factor(data$in_situ_cat))-1

data <- data %>%
  drop_na()

```

2) Set up train / test splits for random CV 
```{r}
#response var
target <- 'in_situ_cat'

#predictor vars
feats <- c("blue", "dWL", "nir", "swir2", "red_to_blue", "red_to_nir", "nir_to_red", "green_to_blue", "nir_sac", "nir_min_red", "mean_temp_14_day", "wind")

set.seed(1000)
train <- data %>% sample_frac(0.8)

test <- data %>% 
  filter(!id %in% train$id)

dtrain <- xgb.DMatrix(data = as.matrix(train[feats]), label = train[target][[1]])

dtest <- xgb.DMatrix(data = as.matrix(test[feats]), label = test[target][[1]])


```


3) Hypertune xgboost parameters and save as 'best_params' 
```{r}

grid_train <- expand.grid(
  max_depth= c(2,3,4),
  subsample = c(.5,.8,1),
  colsample_bytree= c(.5,.8,1),
  eta = c(.01, 0.1),
  min_child_weight= c(1,3,5)
)

hypertune_xgboost = function(train,test, grid){
  
  params <- list(booster = "gbtree", objective = 'multi:softmax', eta=grid$eta ,max_depth=grid$max_depth, 
                 min_child_weight=grid$min_child_weight, subsample=grid$subsample, colsample_bytree=grid$colsample_bytree)
  
  xgb.naive <- xgb.train(params = params, data = dtrain, nrounds = 2000, 
                         watchlist = list(train = train, val = test), 
                         print_every_n =100, early_stopping_rounds = 20, num_class = 3)
  
  summary <- grid %>% mutate(val_loss = xgb.naive$best_score, best_message = xgb.naive$best_msg)
  
  return(summary) 
}

## Hypertune xgboost
xgboost_hypertune <- grid_train %>%
  pmap_dfr(function(...) {
    current <- tibble(...)
    hypertune_xgboost(dtrain,dtest,current)
  })

best_params <- xgboost_hypertune[xgboost_hypertune$val_loss==min(xgboost_hypertune$val_loss),]

best_params <- list(booster = "gbtree", objective = 'multi:softmax',
               eta=best_params$eta,
               max_depth=best_params$max_depth, 
               min_child_weight=best_params$min_child_weight, 
               subsample=best_params$subsample, 
               colsample_bytree=best_params$colsample_bytree)


```


4) Re-train final model with best params , look at evaluation metrics from test data
```{r}

final_model <- xgb.train(params = best_params, data = dtrain, nrounds = 2000, 
                         print_every_n = 20, num_class = 3)

test <- test %>%
  mutate(trophic_predicted = predict(final_model, dtest),
         in_situ_cat = case_when(in_situ_cat ==0~'oligo',
                                 in_situ_cat==1~'mixo',
                                 in_situ_cat==2~'eutro'),
         trophic_predicted = case_when(trophic_predicted==0~'oligo',
                                       trophic_predicted==1~'mixo',
                                       trophic_predicted==2~'eutro'))

cv <- confusionMatrix(factor(test$trophic_predicted),factor(test$in_situ_cat))

cv

plot <- as.data.frame(cv$table)

plot$Prediction <- factor(plot$Prediction, levels=rev(levels(plot$Prediction)))

ggplot(plot, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq), size = 7) +
        scale_fill_gradient(low="white", high="#006a4e") +
        labs(x = "Observed",y = "Predicted", title = "Random CV") +
        scale_x_discrete(labels=c("Oligotrophic", "Mesotrophic", "Eutrophic")) +
        scale_y_discrete(labels=c( "Eutrophic", "Mesotrophic", "Oligotrophic"))

```